{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-28T10:34:22.686961Z",
     "start_time": "2024-07-28T10:34:22.121174Z"
    }
   },
   "source": [
    "import sys \n",
    "import os\n",
    "\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:34:22.690296Z",
     "start_time": "2024-07-28T10:34:22.688070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Verify the project root path\n",
    "print(\"Project root path:\", project_root)\n",
    "\n",
    "# Add the dora_implementation directory to sys.path\n",
    "sys.path.append(os.path.join(project_root, 'dora_implementation'))\n"
   ],
   "id": "574f584fab585ef7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root path: /Users/vitorsousa/Documents/Projects/dora-implementation\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Try LoRA",
   "id": "beb3e45089357644"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:34:22.693812Z",
     "start_time": "2024-07-28T10:34:22.690882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lora_layer import LoRALayer, LinearWithLoRA, LinearWithLoRAMerged\n",
    "from mlp import MultiLayerPerceptron,freeze_linear_layers\n",
    "from torch import nn\n",
    "import torch"
   ],
   "id": "3dc470762e05d3f5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:34:22.698760Z",
     "start_time": "2024-07-28T10:34:22.694327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## single Linear Layer\n",
    "torch.manual_seed(123)\n",
    "layer = nn.Linear(10, 2)\n",
    "x = torch.randn((1,10))\n",
    "print(\"Original output:\", layer(x))"
   ],
   "id": "91fc6e83815da872",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original output: tensor([[0.6639, 0.4487]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:34:22.702940Z",
     "start_time": "2024-07-28T10:34:22.700179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## applying LoRA\n",
    "layer_lora_1 = LinearWithLoRA(layer, rank = 2, alpha= 4)\n",
    "print(\"LoRA output:\", layer_lora_1(x))"
   ],
   "id": "84a3320d976f3500",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA output: tensor([[0.6639, 0.4487]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Since we initialized the weight matrix $B$ with zero values in the LoRA layer, the matrix multiplication between $A$ and $B$ result ina matrix consisted of 0's and doesn't affect the original weights.",
   "id": "c4ff104c4b79ba11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:34:22.706091Z",
     "start_time": "2024-07-28T10:34:22.703593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer_lora_2 = LinearWithLoRAMerged(layer, rank=2, alpha=4)\n",
    "\n",
    "print(\"LoRA output:\", layer_lora_2(x))"
   ],
   "id": "db08e7145819acb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA output: tensor([[0.6639, 0.4487]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Applying LoRA Layers\n",
    "With the implementation using PyTorch modules enable to easily replace a `Linear` layer in an existing neural network with the `LinearWithLoRA` (or `LinearWithLoRAMerged` layers. \n",
    "\n",
    "We can implement the multiplayer perceptron as follows:\n"
   ],
   "id": "dd6fb57cec759473"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:34:22.708291Z",
     "start_time": "2024-07-28T10:34:22.706689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "random_seed = 123\n",
    "learning_rate = 0.005\n",
    "num_epochs = 2\n",
    "\n",
    "# Architecture\n",
    "num_features = 784\n",
    "num_hidden_1 = 128\n",
    "num_hidden_2 = 256\n",
    "num_classes = 10"
   ],
   "id": "80ec0417d8baed4b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:34:22.711019Z",
     "start_time": "2024-07-28T10:34:22.708825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MultiLayerPerceptron(\n",
    "    num_features = num_features, \n",
    "    num_hidden_1= num_hidden_1, \n",
    "    num_hidden_2= num_hidden_2,\n",
    "    num_classes = num_classes,\n",
    ")"
   ],
   "id": "369220755d8d6eb5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:34:22.713224Z",
     "start_time": "2024-07-28T10:34:22.711658Z"
    }
   },
   "cell_type": "code",
   "source": "print(model)",
   "id": "25ac49c1dac7b97d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MLP with LoRA layers",
   "id": "a5cc68bb494f881d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:34:22.716961Z",
     "start_time": "2024-07-28T10:34:22.713742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.layers[0] = LinearWithLoRA(model.layers[0], rank=4, alpha=8)\n",
    "model.layers[2] = LinearWithLoRA(model.layers[2], rank=4, alpha=8)\n",
    "model.layers[4] = LinearWithLoRA(model.layers[4], rank=4, alpha=8)"
   ],
   "id": "65086dd4dd0b5adf",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:34:22.719158Z",
     "start_time": "2024-07-28T10:34:22.717571Z"
    }
   },
   "cell_type": "code",
   "source": "print(model)",
   "id": "dbd3681e904c145f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): LinearWithLoRA(\n",
      "      (linear): Linear(in_features=784, out_features=128, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): LinearWithLoRA(\n",
      "      (linear): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (3): ReLU()\n",
      "    (4): LinearWithLoRA(\n",
      "      (linear): Linear(in_features=256, out_features=10, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "With this model we can freeze the original `Linear` layers and only make the `LoRALayer` layers trainable as follows:",
   "id": "2c3df71dc169ac93"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:34:22.721421Z",
     "start_time": "2024-07-28T10:34:22.719745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "freeze_linear_layers(model)\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.requires_grad}\")"
   ],
   "id": "f03e546465a7e7bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.linear.weight: False\n",
      "layers.0.linear.bias: False\n",
      "layers.0.lora.A: True\n",
      "layers.0.lora.B: True\n",
      "layers.2.linear.weight: False\n",
      "layers.2.linear.bias: False\n",
      "layers.2.lora.A: True\n",
      "layers.2.lora.B: True\n",
      "layers.4.linear.weight: False\n",
      "layers.4.linear.bias: False\n",
      "layers.4.lora.A: True\n",
      "layers.4.lora.B: True\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Bases on the `True`and `False` values we can confirm that onlye th `LoRA` layers are trainable. ",
   "id": "f9610a4ec8e0a92e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# With an Dataset",
   "id": "226ad39b663b35b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:50:31.113297Z",
     "start_time": "2024-07-28T10:50:29.310347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n"
   ],
   "id": "1a694925932d551",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:50:34.883275Z",
     "start_time": "2024-07-28T10:50:34.880042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ],
   "id": "9d0f12189852ecde",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:50:45.217321Z",
     "start_time": "2024-07-28T10:50:45.213993Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "id": "36d35c6ea2e7a4d5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T11:02:50.207540Z",
     "start_time": "2024-07-28T11:02:43.060882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "##########################\n",
    "### MNIST DATASET\n",
    "##########################\n",
    "\n",
    "# Note transforms.ToTensor() scales input images\n",
    "# to 0-1 range\n",
    "train_dataset = datasets.MNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data', \n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ],
   "id": "f27316c5595a5614",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Image batch dimensions: torch.Size([64, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "728de45492257f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
